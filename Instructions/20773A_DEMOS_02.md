# Module 2: Exploring Big Data

- [Module 2: Exploring Big Data](#module-2-exploring-big-data)
    - [Demo 1: Reading Data from SQL Server and HDFS](#demo-1-reading-data-from-sql-server-and-hdfs)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Reading Data stored in SQL Server](#reading-data-stored-in-sql-server)
        - [Reading Data stored in HDFS](#reading-data-stored-in-hdfs)
    - [Demo 2: Transforming, Summarizing, and Cross-tabulating XDF Data](#demo-2-transforming-summarizing-and-cross-tabulating-xdf-data)
        - [Scenario](#scenario)
        - [Transforming XDF data](#transforming-xdf-data)
        - [Summarizing XDF data](#summarizing-xdf-data)
        - [Cross-tabulating XDF data](#cross-tabulating-xdf-data)

## Demo 1: Reading Data from SQL Server and HDFS

### Scenario

In this demonstration, you will see how use R to read datasets stored in a SQL Server database, and access datasets stored in HDFS.

### Preparation

1. Log in to the  VM as **.\\student** with the password **Pa55w.rd**.
2. Follow the instructions in the document **Creating the Hadoop Cluster on Azure** to deploy and configure an Azure HDInsight cluster, if you haven't already done so.
3. Upload the census data to the HDInsight cluster using the following steps:
	1. On the Windows desktop, open a command prompt.
	2. In the command prompt window, run the **putty** command. The putty utility should start and the PuTTY Configuration window should appear.
	3. In the **PuTTY Configuration** window, in the list of saved sessions, click **LON-HADOOP**, click **Load**, and then click **Open**.
	4. In the PuTTY terminal window, run the following commands to connect as the **hdfs** user and create the sample data used by these demos:

        ```Bash
        sudo bash
        su - hdfs
        cd /usr/lib64/microsoft-r/3.3/lib64/R/library/RevoScaleR/SampleData
        hadoop fs -copyFromLocal CensusWorkers.xdf /user/sshuser
        hadoop fs -chmod 777 /user/sshuser/CensusWorkers.xdf
        exit
        exit
        ```

    5. Close the PuTTY terminal window.

4. Additionally, if you haven't already created the **AirlineData** SQL Server database, perform the following steps:
    1. On the Windows desktop, click **Start**, type **Microsoft SQL Server Management Studio**, and then press Enter.
    2. In the **Connect to Server** dialog box, log in to **LON-SQLR** using **Windows authentication**.
    3. In Object Explorer, right-click **Databases**, and then click **New Database**.
    4. In the **New Database** dialog box, in the **Database name** box, type **AirlineData**, and then click **OK**.
    5. Close SQL Server Management Studio.
    6. Start your R development environment of choice (Visual Studio 2017® or RStudio).
    7. Open the R script **E:\\Demofiles\\Mod02\\importAirports.R**.
    8. Run the script.
    9. Close your R development environment without saving any changes.

### Reading Data stored in SQL Server

1. Open your R development environment of choice (RStudio or Visual Studio 2017).
2. Open the R script **Demo1 - SQL Server.R** in the **E:\\Demofiles\\Mod02** folder.
3. Highlight and run the code under the comment **# Connect to SQL Server**. These statements create an **RxSqlServerData** data source that references the **Airports** table in the **AirlineData** database on the **LON-SQLR** server.
4. Highlight and run the code under the comment **# Use R functions to examine the data in the Airports table**. These statements display the first few rows of the table, and then use the **rxGetVarInfo** and **rxSummary** functions to display the columns in the table, and calculate summary information.

### Reading Data stored in HDFS

1. Open the R script **Demo1 - HDFS.R** in the **E:\\Demofiles\\Mod02** folder.
2. Highlight and run the code under the comment **# Create a Hadoop compute context**. These statements open a connection to the Hadoop cluster and set this connection as the compute context.
3. Highlight and run the code under the comment **# List the contents of the /user/sshuser folder in HDFS**. This command uses the Hadoop **fs -ls** command to display the file names from HDFS.
4. Highlight and run the code under the comment **# Connect directly to HFDS on the Hadoop cluster**. These statements create an **RxHdfsFileSystem** object and make it the default file system for the session.
5. Highlight and run the code under the comment **# Create a data source for the CensusWorkers.xdf file**. This statement creates an XDF data source that references the CensusWorkers.xdf file in HDFS.
6. Highlight and run the code under the comment **# Perform functions that read from the CensusWorkers.xdf file**. These statements display the first few lines from the CensusWorkers.xdf file, and generate a summary of the file contents. 

    > **Note**: The **rxSummary** command might take a couple of minutes. This is because Hadoop is optimized to handle very large data files. With a small file such as the one used in this demonstration, the overhead of using Hadoop exceeds the time spent performing any processing.

7. Close your R development environment of choice (RStudio or Visual Studio 2017) without saving any changes.

> **Important**: At the end of this demonstration, make sure that you delete the HDInsight cluster in Azure, otherwise you will run up considerable charges.

## Demo 2: Transforming, Summarizing, and Cross-tabulating XDF Data

### Scenario

In this demonstration, you will see how use R to transform, summarize, and cross-tabulate data held in XDF files.

### Transforming XDF data

1. Using **File Explorer**, go to the folder **E:\\Demofiles\\Mod02**, right-click the file **2000.zip**, and then click **Extract All**.
2. In the **Extract Compressed (Zipped) Folders** dialog box, specify the folder **E:\\Demofiles\\Mod02**, and then click **Extract**.
3. Open your R development environment of choice (RStudio or Visual Studio 2017).
4. Open the R script **Demo2 - Transforming Data.R** in the **E:\\Demofiles\\Mod02** folder.
5. Highlight and run the code under the comment **# Flight delay data for the year 2000**.
6. Highlight and run the statements under the comment **# Examine the raw data**. These statements perform a quick import of the first 1,000 rows of the airport delay data and display the structure of this data. Note the variables names and the number of variables (30).
7. Highlight and run the code under the comment **# Create an XDF file that combines the ArrDelay and DepDelay variables**. These statements import the CSV data into an XDF file, and add a new field called **Delay**. The **rowSelection** argument contains an expression that randomly selects 10 percent of the data in the source file.
8. Highlight and run the code under the comment **# Examine the stucture of the XDF data**. Notice taht there are now 31 variables, including **Delay**.

### Summarizing XDF data

1. Highlight and run the code under the comment **# Generate a quick summary of the numeric data in the XDF file**. This statement uses the **~.** formula to summarize all numeric fields in the XDF file.
2. Highlight and run the code under the comment **# Summarize the delay fields**. This statement generates summaries for the **ArrDelay**, **DepDelay**, and **Delay** fields only. Notice the syntax in the formula.
3. Highlight and run the code under the comment **# Examine Delay broken down by origin airport**. These statements factorize the **Origin** and **Dest** columns using the **rxFactors** function, and generate the summary.

### Cross-tabulating XDF data

1. Highlight and run the code under the comment **# Generate a crosstab showing the average delay**. This statement creates a sparse tabular output showing the average delay that has occurred for flights between each.
2. Highlight and run the code under the comment **# Generate a cube of the same data**. This statement outputs the delay information, but also displays the counts. Note that the cube includes routes that don't exist; they have a delay of NaN, and a count of 0.
3. Highlight and run the code under the comment **# Omit the routes that don't exist**. This statement sets the **removeZeroCounts** argument so that routes that have a count of zero are no longer included.
4. Close your R development environment of choice (RStudio or Visual Studio 2017) without saving any changes.

---

©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
