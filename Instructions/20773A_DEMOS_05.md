# Module 5: Parallelizing Analysis Operations

- [Module 5: Parallelizing Analysis Operations](#module-5-parallelizing-analysis-operations)
    - [Demo 1: Using rxExec to Perform Tasks in Parallel](#demo-1-using-rxexec-to-perform-tasks-in-parallel)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Running a simulation sequentially](#running-a-simulation-sequentially)
        - [Running a simulation using parallel tasks](#running-a-simulation-using-parallel-tasks)
    - [Demo 2: Creating Waiting and Non-waiting Jobs in Hadoop](#demo-2-creating-waiting-and-non-waiting-jobs-in-hadoop)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Uploading data to HDFS on Hadoop](#uploading-data-to-hdfs-on-hadoop)
        - [Running an analysis as a waiting job](#running-an-analysis-as-a-waiting-job)
        - [Running an analysis as a non-waiting job](#running-an-analysis-as-a-non-waiting-job)
    - [Demo 3: Creating and Running a PEMA Object](#demo-3-creating-and-running-a-pema-object)
        - [Scenario](#scenario)
        - [Preparation](#preparation)
        - [Creating a PEMA class generator](#creating-a-pema-class-generator)
        - [Testing the PemaMean class](#testing-the-pemamean-class)
        - [Using the PemaMean class to analyze flight delay data](#using-the-pemamean-class-to-analyze-flight-delay-data)

## Demo 1: Using rxExec to Perform Tasks in Parallel

### Scenario

In this demonstration, you will see how to use parallel tasks in an R analysis.

The demonstration runs a dice game simulation. The rules of the game are:

- If you roll a 7 or 11 on your initial roll, you win.
- If you roll 2, 3, or 12, you lose. 
- If you roll a 4, 5, 6, 8, 9, or 10, then that number becomes your point. You continue rolling until you either roll your point again (you win), or roll a 7 (you lose).

### Preparation

1. Start the VMs if they are not already running. 
2. Log in to the  VM as **.\\student** with the password **Pa55w.rd**.

### Running a simulation sequentially

1. Open your R development environment of choice (RStudio or Visual Studio 2017Â®).
2. Open the R script **Demo1 - dice.R** in the **E:\\Demofiles\\Mod05** folder.
3. Highlight and run the code under the comment **# Connect to R Server**. This code connects to R Server running on the LON-RSVR VM.
4. Highlight and run the code that creates the **playDice** function, under the comment **# Create dice game simulation function**.
5. Highlight and run the statement that runs the **playDice** function, under the comment **# Test the function**. This code should display the message *Win* or *Loss*, depending on the output of the simulation.
6. Highlight and run the code under the comment **# Play the game 100000 times sequentially**. This code uses the **replicate** function to run the **playDice** function. The results are captured and tabulated, showing the percentage of wins and losses in the 100,000 runs of the games. Note the user and system statistics reported by the **system.time** function.
7. Repeat step 6 several times, to get an average of the user and system timings.

### Running a simulation using parallel tasks

1. Highlight and run the code under the comment **# Play the game 100000 times using rxExec**. Note that the code is currently running using the **RxLocalSeq** compute context, so tasks are still being performed sequentially. As a result, the user and system timings might not be much quicker than before (and they could actually be slightly slower).
2. Highlight and run the code under the comment **# Switch to RxLocalParallel**. The time spent running in user mode should be much lower, although the overall elapsed time is likely to be higher in this example.

    The reason for this is that this is a simple simulation using a very small amount of data on a modest server. The overheads of splitting up the job into tasks and running them in parallel actually exceeds any performance benefits gained. However, if the job was much more compute intensive and involving vast amounts of data, then these overheads become a much less significant part of the processing.

    > **Note**: The remote session might be interrupted with the message:
    >
    > ```Text
    > Canceling execution...
    >
    > Error in remoteExecute(line, script = FALSE, displayPlots = displayPlots,  : object 'r_outputs' not found
    > ```
    >
    > If this occurs, type **resume()** in the console to return to the remote session, and then repeat the step.

3. Close your R development environment of choice (RStudio or Visual Studio 2017).

## Demo 2: Creating Waiting and Non-waiting Jobs in Hadoop

### Scenario

In this demonstration, you will see how to create waiting and non-waiting jobs using the Hadoop compute context, and how to cancel a non-waiting job.

### Preparation

1. Start the **20773A-LON-DC**, **20773A-LON-DEV**, **20773A-LON-SQLR**, **20773A-LON-RSVR**, and **MT17B-WS2016-NAT** VMs if they are not already running.
2. Log in to the  VM as **.\\student** with the password **Pa55w.rd**.
3. Follow the instructions in the document **Creating the Hadoop Cluster on Azure** to deploy and configure an Azure HDInsight cluster, if you haven't already done so.
4. Using **File Explorer**, move to the folder **E:\\Demofiles\\Mod05**, and then double-click the file **FlightDelayData.part01.exe**
5. In the **WinRAR self-extracting archive** dialog box, click **Extract**. Overwrite the existing file if prompted.

### Uploading data to HDFS on Hadoop

1. Open your R development environment of choice (RStudio or Visual Studio 2017).
2. Open the R script **Demo2 - nonwaiting.R** in the **E:\\Demofiles\\Mod05** folder.
3. Highlight and run the code under the comment **# Create a Hadoop compute context**. These statements establish a waiting compute context running on the HDInsight cluster.
4. Highlight and run the code under the comment **# Upload the Flight Delay Data**. This statement removes any existing version of the flight delay data, and then copies the latest flight delay data XDF file to HDFS on the HDInsight cluster. This will take two or three minutes to run. 

    > **Note**: the **rxHadoopRemove** function will return FALSE if the file doesn't already exist. You can ignore this status.

    The **rxHadoopCopyFromClient** functions should display the message TRUE if the file is uploaded successfully.

### Running an analysis as a waiting job

1. Highlight and run the code under the comment **# Perform an analysis on the flight data**. These statements use the **rxSummary** function to generate a list of routes (**Origin**/**Dest** pairs), and the number of flights made for each route. The result is stored in the **routes** variable. This summary will be performed as a Hadoop Map/Reduce job. This task will take a couple of minutes to complete.
2. Highlight and run the code under the comment **# Try and sort the data in the Hadoop context**. This code uses the **rxSort** function to sort the results of the summary. However, the way in which **rxSort** works renders it unsuitable for running in a distributed environment such as Hadoop, so the code fails with an error message.
3. Highlight and run the code under the comment **# Use rxExec to run rxSort in a distrubuted context**. This statement uses the **rxExec** function to invoke **rxSort**. You should note that this is more of a workaround to enable you to run this function (and others like it that are not inherently distributable), because, in this case, **rxExec** runs the function as a single task.

    When the sort has completed, the **head** function displays the first few hundred routes, with the most popular ones at the top of the list.

### Running an analysis as a non-waiting job

1. Highlight and run the code under the comment **# Create a non-waiting Hadoop compute context**. This code creates another Hadoop compute context but with the wait flag set to FALSE.
2. Highlight and run the code under the comment **# Perform the analysis again**. This statement runs the same **rxSummary** task as before, but this time it executes as a non-waiting job. The value returned is a job object.
3. Highlight and run the code under the comment **# Check the status of the job**. This statement checks the status of the job. If it is still in progress, it returns the message running. If the job has completed, it returns the message **finished**.
4. Keep running the code under the comment **# Check the status of the job** until it reports the status message **finished**.
5. Highlight and run the code under the comment **# When the job has finished, get the results**. This code uses the **rxGetJobResults** function to retrieve the results of the **rxSummary** function, and then prints the result (it has not been sorted).
6. Highlight and run the code under the comment **# Run the job again**.
7. Highlight and run the code under the comment **# Check the status of the job**. Verify that the job is running.
8. Highlight and run the code under the comment **# Cancel the job**. This statement uses the **rxCancel** function to stop the job and tidy up any resources it was using.

    > **Note**: You can speed up cancellation by setting the **autoCleanup** flag to FALSE when you create the Hadoop compute context. However, this will leave any temporary artifacts and partial results in place on the Hadoop server. You will eventually need to remove these items to avoid filling up server storage.

9. Highlight and run the code under the comment **# Check the status of the job**. The job should now be reported as **missing**.
10. Highlight and run the code under the comment **# Return to the local compute context**. This statement resets your compute context back to the local client VM.
11. Close your R development environment of choice (RStudio or Visual Studio 2017).

> **Important**: At the end of this demonstration, make sure that you delete the HDInsight cluster in Azure, otherwise you will run up considerable charges.

## Demo 3: Creating and Running a PEMA Object

### Scenario

In this demonstration, you will see how to create and use a PEMA object to perform parallel tasks in an R analysis.

### Preparation

1. Start the **20773A-LON-DC**, **20773A-LON-DEV**, **20773A-LON-SQLR**, **20773A-LON-RSVR**, and **MT17B-WS2016-NAT** VMs if they are not already running. 
2. Log in to the  VM as **.\\student** with the password **Pa55w.rd**.
3. Using **File Explorer**, move to the folder **E:\\Demofiles\\Mod05**, and then double-click the file **FlightDelayDataSubset.part1.exe**
4. In the **WinRAR self-extracting archive** dialog box, click **Extract**. Overwrite the existing file if prompted.

### Creating a PEMA class generator

1. Open your R development environment of choice (RStudio or Visual Studio 2017).
2. Open the R script **Demo3 - PemaMean.R** in the **E:\Demofiles\Mod05** folder.
3. Highlight and run the code under the comment **# Create the PemaMean class**. This code creates the **PemaMean** class, which you can use to calculate the mean value of a specified variable in a dataset. The class uses the RevoPemaR framework to perform the calculation in a distributed manner. The class, fields, and methods are the same as those described in the notes in the lesson.

### Testing the PemaMean class

1. Highlight and run the code under the comment **# Instantiate a PemaMean object**. This statement creates a variable named **meanPemaObj** using the **PemaMean** class.
2. Highlight and run the code under the comment **# Connect to R Server**. This creates a remote connection and sets up the environment for RevoPemaR.
3. Highlight and run the code under the comment **# Copy the PemaMean object to the R server environment for testing**. This copies the **PemaMean** object from the local session to the remote session running on R server.
4. Highlight and run the code under the comment **# Create some test data**. This code creates a data frame with a single variable named **x**. The variable contains 1,000 random values. Note that the random number generated is seeded with a specific value to enable the test to be repeatable.
5. Highlight and run the code under the comment **# Run the analysis**. This code uses the **pemaCompute** function to deploy the **meanPemaObj** object to the distributed environment and start it running. The parameters specify the dataset, and the variable for which the mean should be calculated. The value returned is displayed. It should be 0.04619816.
6. Highlight and run the code under the comment **# Examine the internal fields of the PemaMean object**. This code retrieves the data stored in the **sum**, **mean**, and **totalValidObs** fields of the object. Note that the number of valid observations is 1000.
7. Highlight and run the code under the comment **# Create some more test data**. This code creates another dataset of 1000 seeded random numbers.
8. Highlight and run the code under the comment **# Run the analysis again, but include the previous results**. This repeats the analysis, but sets the **initPema** argument of the **pemaCompute** function to FALSE. This prevents the PEMA framework from invoking the **initialize** function in the PEMA object, so the fields are not reset. The result should be -0.006803199.
9. Highlight and run the code under the comment **# Examine the internal fields of the PemaMean object again**. This time, note that the number of valid observations is 2000.

### Using the PemaMean class to analyze flight delay data

1. Highlight and run the code under the comment **# Perform an analysis against the flight delay data**. This code copies a test subset of the flight delay data to the remote session, and then uses the **PemaMean** object to analyze the **Delay** variable in this data. The result is the mean delay for all flights.
2. Close your R development environment of choice (RStudio or Visual Studio 2017).

---

Â©2018 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
